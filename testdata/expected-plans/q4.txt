DataFusion Logical Plan
=======================

Sort: orders.o_orderpriority ASC NULLS LAST
  Projection: orders.o_orderpriority, count(*) AS order_count
    Aggregate: groupBy=[[orders.o_orderpriority]], aggr=[[count(Int64(1)) AS count(*)]]
      Projection: orders.o_orderpriority
        LeftSemi Join: orders.o_orderkey = __correlated_sq_1.l_orderkey
          Projection: orders.o_orderkey, orders.o_orderpriority
            Filter: orders.o_orderdate >= Date32("1995-04-01") AND orders.o_orderdate < Date32("1995-07-01")
              TableScan: orders projection=[o_orderkey, o_orderdate, o_orderpriority], partial_filters=[orders.o_orderdate >= Date32("1995-04-01"), orders.o_orderdate < Date32("1995-07-01")]
          SubqueryAlias: __correlated_sq_1
            Projection: lineitem.l_orderkey
              Filter: lineitem.l_receiptdate > lineitem.l_commitdate
                TableScan: lineitem projection=[l_orderkey, l_commitdate, l_receiptdate], partial_filters=[lineitem.l_receiptdate > lineitem.l_commitdate]

DataFusion Physical Plan
========================

SortPreservingMergeExec: [o_orderpriority@0 ASC NULLS LAST]
  SortExec: expr=[o_orderpriority@0 ASC NULLS LAST], preserve_partitioning=[true]
    ProjectionExec: expr=[o_orderpriority@0 as o_orderpriority, count(*)@1 as order_count]
      AggregateExec: mode=FinalPartitioned, gby=[o_orderpriority@0 as o_orderpriority], aggr=[count(*)]
        CoalesceBatchesExec: target_batch_size=8192
          RepartitionExec: partitioning=Hash([o_orderpriority@0], 2), input_partitions=2
            AggregateExec: mode=Partial, gby=[o_orderpriority@0 as o_orderpriority], aggr=[count(*)]
              CoalesceBatchesExec: target_batch_size=8192
                HashJoinExec: mode=Partitioned, join_type=LeftSemi, on=[(o_orderkey@0, l_orderkey@0)], projection=[o_orderpriority@1]
                  CoalesceBatchesExec: target_batch_size=8192
                    RepartitionExec: partitioning=Hash([o_orderkey@0], 2), input_partitions=2
                      CoalesceBatchesExec: target_batch_size=8192
                        FilterExec: o_orderdate@1 >= 1995-04-01 AND o_orderdate@1 < 1995-07-01, projection=[o_orderkey@0, o_orderpriority@2]
                          ParquetExec: file_groups={ ... }, projection=[o_orderkey, o_orderdate, o_orderpriority], predicate=o_orderdate@4 >= 1995-04-01 AND o_orderdate@4 < 1995-07-01, pruning_predicate=CASE WHEN o_orderdate_null_count@1 = o_orderdate_row_count@2 THEN false ELSE o_orderdate_max@0 >= 1995-04-01 END AND CASE WHEN o_orderdate_null_count@1 = o_orderdate_row_count@2 THEN false ELSE o_orderdate_min@3 < 1995-07-01 END, required_guarantees=[]
                  CoalesceBatchesExec: target_batch_size=8192
                    RepartitionExec: partitioning=Hash([l_orderkey@0], 2), input_partitions=2
                      CoalesceBatchesExec: target_batch_size=8192
                        FilterExec: l_receiptdate@2 > l_commitdate@1, projection=[l_orderkey@0]
                          ParquetExec: file_groups={ ... }, projection=[l_orderkey, l_commitdate, l_receiptdate], predicate=l_receiptdate@12 > l_commitdate@11

DataFusion Ray Distributed Plan
===========

Query Stage #0 (2 -> 2):
ShuffleWriterExec(stage_id=0, output_partitioning=Hash([Column { name: "o_orderkey", index: 0 }], 2))
  CoalesceBatchesExec: target_batch_size=8192
    FilterExec: o_orderdate@1 >= 1995-04-01 AND o_orderdate@1 < 1995-07-01, projection=[o_orderkey@0, o_orderpriority@2]
      ParquetExec: file_groups={ ... }, projection=[o_orderkey, o_orderdate, o_orderpriority], predicate=o_orderdate@4 >= 1995-04-01 AND o_orderdate@4 < 1995-07-01, pruning_predicate=CASE WHEN o_orderdate_null_count@1 = o_orderdate_row_count@2 THEN false ELSE o_orderdate_max@0 >= 1995-04-01 END AND CASE WHEN o_orderdate_null_count@1 = o_orderdate_row_count@2 THEN false ELSE o_orderdate_min@3 < 1995-07-01 END, required_guarantees=[]

Query Stage #1 (2 -> 2):
ShuffleWriterExec(stage_id=1, output_partitioning=Hash([Column { name: "l_orderkey", index: 0 }], 2))
  CoalesceBatchesExec: target_batch_size=8192
    FilterExec: l_receiptdate@2 > l_commitdate@1, projection=[l_orderkey@0]
      ParquetExec: file_groups={ ... }, projection=[l_orderkey, l_commitdate, l_receiptdate], predicate=l_receiptdate@12 > l_commitdate@11

Query Stage #2 (2 -> 2):
ShuffleWriterExec(stage_id=2, output_partitioning=Hash([Column { name: "o_orderpriority", index: 0 }], 2))
  AggregateExec: mode=Partial, gby=[o_orderpriority@0 as o_orderpriority], aggr=[count(*)]
    CoalesceBatchesExec: target_batch_size=8192
      HashJoinExec: mode=Partitioned, join_type=LeftSemi, on=[(o_orderkey@0, l_orderkey@0)], projection=[o_orderpriority@1]
        CoalesceBatchesExec: target_batch_size=8192
          ShuffleReaderExec(stage_id=0, input_partitioning=Hash([Column { name: "o_orderkey", index: 0 }], 2))
        CoalesceBatchesExec: target_batch_size=8192
          ShuffleReaderExec(stage_id=1, input_partitioning=Hash([Column { name: "l_orderkey", index: 0 }], 2))

Query Stage #3 (2 -> 2):
ShuffleWriterExec(stage_id=3, output_partitioning=Hash([Column { name: "o_orderpriority", index: 0 }], 2))
  SortExec: expr=[o_orderpriority@0 ASC NULLS LAST], preserve_partitioning=[true]
    ProjectionExec: expr=[o_orderpriority@0 as o_orderpriority, count(*)@1 as order_count]
      AggregateExec: mode=FinalPartitioned, gby=[o_orderpriority@0 as o_orderpriority], aggr=[count(*)]
        CoalesceBatchesExec: target_batch_size=8192
          ShuffleReaderExec(stage_id=2, input_partitioning=Hash([Column { name: "o_orderpriority", index: 0 }], 2))

Query Stage #4 (1 -> 1):
SortPreservingMergeExec: [o_orderpriority@0 ASC NULLS LAST]
  ShuffleReaderExec(stage_id=3, input_partitioning=Hash([Column { name: "o_orderpriority", index: 0 }], 2))

